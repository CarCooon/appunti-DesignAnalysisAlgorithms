\chapter{Pattern Matching}
\label{cap:PatternMatching}



Introduciamo di seguito la terminologia di base:
\begin{itemize}
    \item \(\Sigma\) : l'alfabeto, ovvero l'insieme di caratteri possibili.
    \item \(|\Sigma|\) : la dimensione dell'alfabeto.
    \item Stringa \( S \) : una sequenza finita di caratteri appartenenti all'alfabeto \(\Sigma\), di lunghezza \( m \).
    \item \(S[i]\) : il carattere alla posizione \( i \) della stringa \( S \).
    \item \(S[i..j]\) : la sottostringa di \( S \) che va dall'indice \( i \) all'indice \( j \).
        \begin{itemize}
            \item In Python: $S$[i:j+1] 
        \end{itemize}
    \item \(S[0..k]\) : prefisso di lunghezza \( k+1 \) della stringa \( S \).
        \begin{itemize}
            \item In Python: $S$[:k+1]
        \end{itemize}
    \item \(S[j..m-1]\) : suffisso di lunghezza \( m-j \) della stringa \( S \). 
        \begin{itemize}
            \item In Python: $S$[j:]
        \end{itemize}
\end{itemize}

\noindent
Nel classico problema di pattern matching, ci viene data una stringa di testo $T$ di lunghezza $n$ e una stringa di pattern $P$ di lunghezza $m$, e vogliamo scoprire se $P$ è una sottostringa di $T$. In tal caso, potremmo voler trovare l'indice più basso $j$ all'interno di $T$ in cui inizia $P$, in modo che $T[j..j+m-1]$ sia uguale a $P$, o forse trovare tutti gli indici di $T$ in cui inizia il pattern $P$.

\clearpage
\section{Brute Force}
Il metodo più semplice per risolvere il problema del pattern matching è il metodo \textit{brute force}. L'idea alla base di questo metodo è di confrontare il pattern $P$ con ogni possibile sottostringa di $T$ di lunghezza $m$. In particolare, per ogni indice $i$ da $0$ a $n-m$, confrontiamo la sottostringa $T[i..i+m-1]$ con il pattern $P$. Se troviamo una corrispondenza, restituiamo l'indice $i$.

\vspace{1\baselineskip}
\begin{lstlisting}
def find_brute(T, P):
    """Return the lowest index of T at which substring P begins (or else -1)."""
    n, m = len(T), len(P)  # introduce convenient notations
    for i in range(n-m+1):  # try every potential starting index within T
        k = 0  # an index into pattern P
        while k < m and T[i + k] == P[k]:  # kth character of P matches
            k += 1
        if k == m:  # if we reached the end of pattern,
            return i  # substring T[i:i+m] matches P
    return -1  # failed to find a match starting with any i
\end{lstlisting}
\vspace{1\baselineskip}


\subsection*{Performance}
L'algoritmo consiste in due cicli annidati, con il ciclo esterno che scorre tutti i possibili indici iniziali del pattern nel testo $T$, e il ciclo interno che scorre ogni carattere del pattern $P$, confrontandolo con il suo potenziale carattere corrispondente nel testo. Pertanto, la correttezza dell'algoritmo deriva direttamente da questo approccio di ricerca esaustiva.

Il tempo di esecuzione del pattern matching tramite \emph{Brute Force} nel caso peggiore non è buono poiché per ogni indice candidato in $T$, possiamo eseguire fino a $m$ confronti di caratteri per scoprire che $P$ non corrisponde a $T$ all'indice corrente. Dal blocco di codice si può osservare che il ciclo $for$ esterno viene eseguito al massimo $n-m+1$ volte e il ciclo $while$ interno viene eseguito al massimo $m$ volte. Pertanto, il tempo di esecuzione nel caso peggiore è $O(n m)$.

\clearpage
\subsection*{Esempio}
Supponiamo di avere un testo 
$$ T = \text{"abacaabaccabacabaabb"} $$
e un pattern 
$$ P = \text{"abacab"} $$

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/PatternMatching/ex_BruteForce.png}
    \caption{Esempio di Pattern Matching con algoritmo Brute Force. L'algoritmo esegue 27 confronti tra caratteri, numerati in figura.}
\end{figure}


\clearpage
\section{L'algoritmo di Boyer-Moore}
Come vedremo tra poco, non è sempre necessario confrontare ogni carattere del pattern con il testo. L'algoritmo di \emph{Boyer-Moore} sfrutta questa osservazione per saltare alcune posizioni nel testo, riducendo così il numero di confronti necessari. 

L'idea principale dell'algoritmo di \emph{Boyer-Moore} è di migliorare l'efficienza dell'algoritmo \emph{Brute Force} utilizzando due tecniche (euristiche) principali:

\begin{itemize}
    \item \textbf{Looking-Glass Heuristic}: Quando si confrontano i caratteri del pattern con il testo, si inizia dal carattere più a destra del pattern e si procede verso sinistra.
    \item \textbf{Character-Jump Heuristic}: Durante la verifica di un possibile piazzamento di $P$ in $T$, un mismatch tra $T[i] = c$ e $P[k]$ viene gestito come segue:
    
    Supponiamo che $T[i] \neq P[k]$ e $T[i] = c$.
        \begin{itemize}
            \item Se $c$ non appare in $p$, $p$ può essere "spostato" completamente oltre $T[i]$ ($P[0]$ viene allineato con $T[i+1]$).
            \item Altrimenti, $T[i]$ viene allineato con l'ultima occorrenza di $c$ in $P$.
        \end{itemize}
\end{itemize}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{immagini/PatternMatching/ex_BoyerMoore.png}
    \caption{Una semplice dimostrazione dell'algoritmo di Boyer-Moore. Nel primo confronto si ha $T[4] \neq P[4]$ con $T[4] = \text{'e'}$ che non è presente in $P$, per cui spostiamo $P$ oltre $T[4]$. Nel secondo confronto si ha $T[9] \neq P[4]$ con $T[9] = \text{'s'}$ che è presente in $P$, in particolare l'ultima occorrenza di 's' è in $P[2]$, per cui allineiamo $P[2]$ con $T[9]$.}
    \label{exBoyerMoore}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.8\textwidth]{immagini/PatternMatching/ex2_BoyerMoore.png}
    \caption{Esempio completo che mostra il numero di confronti.}
    \label{ex2BoyerMoore}
\end{figure}

\clearpage
\noindent
Per formalizzare l'algoritmo di \emph{Boyer-Moore} possiamo generalizzare il funzionamento come di seguito:

\begin{itemize}
    \item Quando viene trovata una corrispondenza (a partire dall'ultimo carattere del pattern), l'algoritmo continua cercando di estendere la corrispondenza con il penultimo carattere del pattern nel suo allineamento corrente. Questo processo continua fino a quando tutti i caratteri del pattern sono stati confrontati con esito positivo o fino a quando si verifica un mismatch.
    \item Quando si verifica un mismsatch, e il carattere del testo che ha causato il mismatch non è presente nel pattern, il pattern viene spostato completamente oltre quel carattere del testo. Se il carattere del testo è presente da qualche altra parte nel pattern, dobbiamo considerare due diversi casi a seconda che la sua ultima occorrenza sia $(a)$ precedente o $(b)$ successiva al carattere del pattern che era allineato con il carattere del testo che ha causato il mismatch.
\end{itemize}

Questi due casi sono rappresentati in figura \ref{fig:BM_mismatch_cases} e approfonfiti di seguito:
\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/PatternMatching/BM_mismatch_cases.png}
    \caption{Indichiamo con $i$ l'indice del carattere non corrispondente nel testo, con $k$ l'indice corrispondente nel pattern e con $j$ l'indice dell' ultima occorrenza di $T[i]$ all'interno del pattern. Distinguiamo due casi: \textbf{(a)} $j < k$, nel qual caso spostiamo il pattern di $k-j$ unità, e quindi l'indice $i$ avanza di $m-(j +1)$ unità; \textbf{(b)} $j > k$, nel qual caso spostiamo il pattern di un'unità, e l'indice $i$ avanza di $m-k$ unità.
    N.B. $m$ è la lunghezza del pattern.}
    \label{fig:BM_mismatch_cases}
\end{figure}

\clearpage
\noindent
Nel caso di \ref{fig:BM_mismatch_cases}(b), il pattern viene spostato di una sola unità a destra. Sarebbe sicuramente più produttivo spostare il pattern a destra fino a quando l'ultima occorrenza di $T[i]$ nel pattern non è allineata con $T[i]$, ma questo richiederebbe un ulteriore calcolo per la ricerca della nuova occorrenza. 

L'efficienza dell'algoritmo di \emph{Boyer-Moore} risiede nell'utilizzo di una funzione di pre-elaborazione, $L(c)$, chiamata \textbf{last occurrence function} che consente di determinare rapidamente l'ultima occorrenza di un carattere nel pattern. Questa funzione viene calcolata una sola volta prima dell'inizio del processo di ricerca e viene utilizzata ogni volta che si verifica un mismatch.
$$
\forall c \in \Sigma, \quad L(c) = 
\begin{cases} 
   \max \{ i \mid P[i] = c \} & \text{se } c \in P \\
   -1 & \text{se } c \notin P 
\end{cases}
$$

\noindent
Per esempio, se abbiamo 
$\Sigma = \{ \text{'a'}, \text{'b'}, \text{'c'}, \text{'d'} \}$ 
e 
$P = \text{"abacab"}$
:
\begin{table}[h]
    \centering
    % Aumenta lo spazio orizzontale (default è 6pt)
    \setlength{\tabcolsep}{18pt} 
    % Aumenta lo spazio verticale (default è 1)
    \renewcommand{\arraystretch}{1.5}

    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{c} & \textbf{'a'} & \textbf{'b'} & \textbf{'c'} & \textbf{'d'} \\
        \hline
        \textbf{$L(c)$} & 4 & 5 & 3 & -1 \\
        \hline
    \end{tabular}
\end{table}

\noindent
Possiamo modellare $L$ come una \emph{Map} che ha per chiavi i caratteri dell'alfabeto e per valori gli indici delle loro ultime occorrenze nel pattern (ad esempio, in Python possiamo usare un dizionario).
La Map $L$ può essere costruita in tempo $O(m + |\Sigma|)$ dove $m$ è la lunghezza del pattern e $|\Sigma|$ è la dimensione dell'alfabeto.

\vspace{1\baselineskip}
\begin{lstlisting}
def last_occurrence(p, sigma):
    """Return the last-occurrence map L for pattern p over alphabet sigma."""
    L = {c:-1 for c in sigma}  # initialize all characters to -1
    for i in range(len(p)):
        L[p[i]] = i  # update with last occurrence of character p[i]
    return L
\end{lstlisting}

\clearpage
\begin{lstlisting}
def find_boyer_moore(T, P):
    """Return the lowest index of T at which substring P begins (or else -1)."""
    n, m = len(T), len(P)   # introduce convenient notations
    if m == 0:
        return 0            # trivial search of empty pattern
    
    # last occurrence function
    last = {}               # build the last-occurrence map
    for k in range(m):
        last[P[k]] = k      # later occurrence overwrites

    # align end of pattern at index m-1 of text
    i = m-1               #an index into T
    k = m-1                 #an index into P
    while i < n:
        if T[i] == P[k]:    # a matching character
            if k == 0:      
                return i    # pattern begins at index i of text
            else:
                i -= 1      # examine previous character
                k -= 1      # of both T and P
        else:
            j = last.get(T[i], -1)  # last(T[i]) is -1 if not found
            i += m-min(k, j+1)      # case analysis for jump step
            k = m-1                 # restart at end of pattern
    return -1   
\end{lstlisting}
\vspace{1\baselineskip}

\subsection*{Performance}
La versione semplificata dell'algoritmo di Boyer-Moore presentata qui ha un tempo di esecuzione di $O(n m + |\Sigma|)$, in quanto la last-occurrence function richiede $O(m + |\Sigma|)$ tempo per essere costruita e la ricerca del pattern richiede $O(n m)$. 

Il caso peggiore si verifica quando si ha una coppia del tipo: 
$$T = \text{"aaa...aaa"} \quad P = \text{"baa...aaa"}$$
In questo caso, l'algoritmo di Boyer-Moore si comporta come l'algoritmo Brute Force, eseguendo $O(n m)$ confronti tra caratteri.

Tuttavia, l'algoritmo originale di Boyer-Moore utilizza euristiche più avanzate ed efficienti che consentono di ottenere un tempo di esecuzione medio di $O(n + m + |\Sigma|)$.

\clearpage
\subsection*{Esempio}
Supponiamo di avere un testo 
$$ T = \text{"abacaabadcabacabaabb"} $$
e un pattern 
$$ P = \text{"abacab"} $$

\begin{figure}[!ht]
    \centering
    \includegraphics[width=1\textwidth]{immagini/PatternMatching/BM_Lfunction.png}
    \caption{Esempio di Pattern Matching con algoritmo di Boyer-Moore, con anche la tabella delle last occurrence. L'algoritmo esegue 13 confronti tra caratteri, numerati in figura.}
\end{figure}


\clearpage
\section{L'algoritmo di Knuth-Morris-Pratt}
